### 처리율 제한 장치란?

- 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치
- 예를 들어 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.

### API에 처리율 제한 장치를 두면 좋은점?

1. Dos 공격에 의한 자원 고갈을 방지 가능 → 추가 요청에 대해서 처리를 중단함으로써 Dos 공격을 방지
    - ex) 트위터는 3시간동안 300개의 트윗만 올릴 수 있도록 제한하고 있음
2. 비용을 절감한다.
    - 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있음
3. 서버 과부하를 막는다.

## 1단계 문제 이해 및 설계 범위 확정

**요구사항**

- 설정된 처리율을 초과하는 요청은 정확하게 제한
- 낮은 응답시간 : 이 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어서는 곤란
- 가능한 한 적은 메모리를 써야 함
- 분산형 처리율 제한(distributed rate limiting) : 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
- 예외처리 : 요청이 제한된다면 그 사실을 사용자에게 분명학 보여주어야 한다.
- 높은 결함 감내성(fault tolerance) : 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어선는 안된다.

## 2단계 개략적 설계안 제시 및 동의 구하기

**처리율 제한 장치를 어디에 둘 것인가?**

- 클라이언트에 두면 안되는 이유 :  클라이언트 요청은 쉽게 위변조가 가능하기 때문
- 서버 측에 두는 방법
    ![KakaoTalk_Photo_2024-04-07-11-57-14](https://github.com/HoChangSUNG/mentoring/assets/76422685/be47a984-3f86-434d-a1b1-d15c2cf8b02d)
    
- 처리율 제한 미들웨어를 만들어 해당 미들웨어가 API로 가는 요청을 통제하도록 하는 방법
    ![KakaoTalk_Photo_2024-04-07-11-59-09](https://github.com/HoChangSUNG/mentoring/assets/76422685/5f97acb7-47d7-4186-9268-68042483dfcd)
    
- **처리율 제한 기능 설계 시 중요한 점**
    - 서버에 둘지, 게이트웨이(미들웨어)에 둘지 정답은 없다.
    - 일반적으로 사용되는 지침
        1. 사업 필요에 맞는 처리율 제한 알고리즘을 찾아라
        2. 여러분의 설계가 마이크로서비스에 기반하고 있고 사용자 인증이나 IP 허용목록 관리 등을 처리하기 위해 API게이트웨이를 이미 설계에 포함시켰다면 처리율 제한 기능도 게이트웨이에 포함시켜야 할 수 있다.
        3. 처리율 제한 서비스를 직접 만드는 것은 시간이 걸리기 때문에 상용 API 게이트웨이를 쓰는 것이 바람직하다.

## 처리율 제한 알고리즘

1. 토큰 버킷(token bucket)
2. 누출 버킷(leaky bucket)
3. 고정 윈도 카운터(fixed window counter)
4. 이동 윈도 로그(sliding window log)
5. 이동 윈도 카운터(sliding window counter)

### 토큰 버킷 알고리즘

- 간단하고 알고리즘에 대한 사람들의 이해도가 높은 편, 인터넷 기업들이 보편적으로 사용

**동작원리**

- 토큰 버킷 : 지정된 용량을 갖는 컨테이너, 사전 설정된 양의 토큰이 주기적으로 채워지고, 토큰이 꽉 찬 버킷에는 더 이상의 토큰이 추가되지 않음
1. 각 요청이 처리될 때마다 하나의 토큰을 사용, 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사
    - 충분한 토큰이 있는 경우 → 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달
    - 충분한 토큰이 없는 경우 → 해당 요청은 버려진다.
        
        ![KakaoTalk_Photo_2024-04-07-12-00-24](https://github.com/HoChangSUNG/mentoring/assets/76422685/fd4f3677-2b7e-49dd-9e37-c36ac2c83f2d)
        ![KakaoTalk_Photo_2024-04-07-12-01-15](https://github.com/HoChangSUNG/mentoring/assets/76422685/d2925e11-8a70-4b7a-bf09-c0ddde2cc785)
        

**버킷은 몇개나 사용해야 하는가?**

- 공급 제한 규칙에 따라 달라짐
    - 통상적으로 API 엔드포인트마다 별도의 버킷을 두는 경우 → API 마다 별도의 버킷을 사용
    - IP 주소별로 처리율 제한을 적용하는 경우 → IP 주소별로 버킷을 하나씩 할당
    - 시스템의 처리율을 초당 10,000개 요청으로 제한하는 경우 → 모든 요청이 하나의 버킷을 공유하도록 함
    

**장점**

- 구현이 쉽고 짧은 시간에 집중되는 트랙픽도 처리 가능
- 메모리 사용 측면에서 효율적

**단점**

- 버킷 크기와 토큰 공급률이라는 인자를 가지는데 이 값을 적절하게 튜닝하는 것이 까다로움
    - 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
    - 토큰 공급률 : 초당 몇 개의 토큰이 버킷에 공급되는가

### 누출 버킷 알고리즘

- 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다름
- FIFO 큐로 구현
- 버킷 크기와 처리율
    - 버킷 크기 : 큐 사이즈와 같은 값, 큐에는 처리될 항목이 저장
    - 처리율 : 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값

**동작원리**

![KakaoTalk_Photo_2024-04-07-12-02-50 001](https://github.com/HoChangSUNG/mentoring/assets/76422685/81f3267c-53b8-48e2-bbe3-e68038733fb4)

1. 요청이 도착하면 큐가 차있는지 확인하고, 큐가 비어있는 자리가 있다면 큐에 요청을 추가한다.
2. 큐가 가득 차 있는 경우 새 요청은 버린다.
3. 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

**장점**

- 큐 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
- 고정된 처리율을 가지고 있어 안정적 출력이 필요한 경우 적합

**단점**

- 단시간에 많은 트래픽이 몰리는 경우 큐에 요청이 많아 쌓이고 그 요청을 제때 처리 못하면 최신 요청들은 버려지게 됨

### 고정 윈도 카운터 알고리즘

**동작 방식**

![KakaoTalk_Photo_2024-04-07-12-02-50 002](https://github.com/HoChangSUNG/mentoring/assets/76422685/7818e7f8-f050-4524-a6b5-78700189547f)

- 타임라인을 고정된 간격의 window로 나누고, 각 윈도우마다 카운터를 붙인다.
- 요청이 접수될 때마다 카운터 값을 1씩 증가
- 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

**문제점**

- 윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도우에 할당된 양보다 더 많은 요청이 처리될 수 있다는 점

**장점**

- 메모리 효율이 좋다
- 이해하기 쉽다
- 윈도우가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

**단점**

- 윈도우 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 됨

### 이동 윈도 로깅 알고리즘

- 고정 윈도 카운터 알고리즘의 문제점을 해결
- 타임스탬프(timestamp)를 추적, 타임스탬프 데이터는 보통 레디스(Redis)의 정렬 집합 같은 캐시에 보관

**동작 방식**

- 새 요청이 오면 만료된 타임스탬프를 제거
    - 만료된 타임스탬프 → 값이 현재 윈도우의 시작 시점보다 오래된 타임스탬프를 말한다.
- 새 요청의 타임스탬프를 로그에 추가
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달, 그렇지 않으면 처리를 거부

### 이동 윈도 카운터 알고리즘

- 고정 윈도우 카운터 알고리즘 + 이동 윈도우 로깅 알고리즘을 결합한 것
    ![KakaoTalk_Photo_2024-04-07-12-04-51](https://github.com/HoChangSUNG/mentoring/assets/76422685/b4dda927-3a61-4be4-b424-749ba40abbb3)
    

**장점**

- 이전 시간대의 평균 처리율에 따라 현재 윈도우의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.

**단점**

- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨

## 3단계 상세 설계

### 처리율 한도 초과 트래픽의 처리

- 어떤 요청이 한도 제한이 걸리면 API는 http 429 응답(too many request)를 클라이언트에게 보낸다.

**처리율 제한 장치가 사용하는 HTTP 헤더**

- 클라이언트는 자기 요청이 처리율 제한에 걸렸는지(throttle) 어떻게 감지하는가?
    - HTTP 응답 헤더에 위와 관련된 헤더를 넣어 보내면 된다.
        - X-Ratelimit-Remaining : 윈도우 내에 남은 처리 가능 요청 수
        - X-Ratelimit-Limit : 매 윈도우마다 클라이언트가 전송할 수 있는 요청의 수
        - X-RateLimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
        

### **상세 설계**

![KakaoTalk_Photo_2024-04-07-12-06-31](https://github.com/HoChangSUNG/mentoring/assets/76422685/b3b4e85c-29d5-492c-8241-c03110d991a7)

1. 처리율 제한 규칙은 디스크에 보관
작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장
2. 클라이언트가 요청을 서버에 보내면 처리율 제한 미들웨어에 요청이 도달
3. 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져옴
카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져옴
4. 해당 요청이 처리율 제한에 걸리지 않은 경우 API 서버로 보냄
5. 해당 요청이 처리율 제한에 걸리면 429 too many requests를 클라이언트에게 보냄
해당 요청은 그대로 버릴 수도 있고 메시지 큐에 보관할 수도 있음

### 분산 환경에서의 처리율 제한 장치의 구현

처리율 제한 장치 구현은 어렵지 않지만, 여러 대의 서버와 병렬 스레드를 지원하도록 시스템 확장하는 것은 아래 두가지 문제를 풀어야 함

- 경쟁 조건
- 동기화

**경쟁 조건**

- 가장 잘 알려진 해결책은 락이나, 시스템의 성능을 상당히 떨어뜨림
- 따라서 락 대신 루아 스크립트 혹은 정렬 스크립트라는 레디스 자료구조를 사용하자

**동기화 이슈**

- 수백만 사용자를 지원하려면 한 대의 처리율 제한 장치 서버로는 충분하지 않을 수 있고, 여려 대의 처리율 제한 장치를 두면 동기화가 필요해짐
- 웹 계층은 무상태이기 때문에 항상 같은 처리율 제한 장치로 보내지 않을 수 있고, 처리율 제한을 올바르게 수행하지 못함
- 해결책
    - 고정 세션을 활용 → 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보내도록 함, but 규모면에서 확장 가능하지도 않고, 유연하지 않아 추천 x
    - 레디스와 같은 중앙 집중형 데이터 저장소를 사용하는 것이 좋음
        
        ![KakaoTalk_Photo_2024-04-07-12-07-55.jpeg](https://prod-files-secure.s3.us-west-2.amazonaws.com/9cfd1df3-e748-4be6-a380-aa3c47f0cd8e/7715bbc0-2682-4c8f-beb0-22672b6f376c/KakaoTalk_Photo_2024-04-07-12-07-55.jpeg)
        

**성능 최적화**

데이터 센터를 지원하는 문제 → 데이터 센터에서 멀리 떨어진 사용자를 지원하려면 지연시간이 증가하는데, edge 서버를 이용해 사용자의 트래픽을 가장 가까운 edge 서버로 전달하여 지연시간을 줄임

**모니터링**

- 처리율 제한 장치 설치 이후, 효과적으로 동작하는지 데이터를 모을 필요가 있음
- 모니터링을 통해 확인하려는 것
    1. 채택된 처리율 제한 알고리즘이 효과적이다.
    2. 정의한 처리율 제한 규칙이 효과적이다.
    
    ex)
    
    - 처리율 제한 규칙이 너무 빡빡하게 설정되면 많은 유효 요청이 처리되지 못하고 버려짐 → 규칙을 완화
    - 세일 이벤트로 트래픽 급증 시, 처리율 제한 장치가 비효율적으로 동작한다면, 그런 트래픽 패턴을 처리할 수 있도록 알고리즘을 바꾸는 것을 생각해봐야 함. → 이런 상황에서는 토큰 버킷이 적합
    

## 마무리

시간이 허락될때 언급해보면 좋은 점

- 경성(hard) 또는 연성(soft) 처리율 제한
    - 경성 처리율 제한 : 요청의 개수는 임계치를 절대 넘어설 수 없다.
    - 연성 처리율 제한 : 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다.
- 다양한 계층에서의 처리율 제한
    - 응용 계층에서의 처리율 제한만 보았지만, 다른 계층에서의 처리율 제한도 가능
    - ex) Iptables 사용시 IP 주소에 처리율 제한을 적용하는 것이 가능
- 처리율 제한을 회피하는 방법. 클라이언트를 어떻게 설계하는 것이 최선인가?
    - 클라이언트 측 캐시를 사용해 API 호출 횟수를 줄임
    - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 함
    - 재시도(retry) 로직을 구현할 때는 충분한 back-off 시간을 둔다.
